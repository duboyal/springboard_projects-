{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import datetime\n",
    "from pytrends.request import TrendReq\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now TEXT BLOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df2 = pd.read_csv('LatestReddit/THIS/DONE/ETH/df_mega_eth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int_time = [int(item) for item in df2['timestamp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2['timestamp'] = [datetime.datetime.fromtimestamp(item) for item in int_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = df2[df2.text.str.contains(\"[deleted]\") == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2['text'] = [str(item) for item in df2['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "textblob_objects = [TextBlob(item) for item in df2['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent_polarity = [item.sentiment.polarity for item in textblob_objects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent_subjectivity = [item.sentiment.polarity for item in textblob_objects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2['sent polarity'] = sent_polarity\n",
    "df2['sent subjectivity'] = sent_subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2['sent polarity'] =  df2['sent polarity'] +0.9765625+0.0234375\n",
    "df2['sent subjectivity']= df2['sent subjectivity']+0.9765625+0.0234375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df2['sent label'] = ['pos' if item > 1.05 else 'neg' if item < 0.96 else 'neu' for item in df2['sent polarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2['sent label'] = ['pos' if item > 1.05 else 'neg' for item in df2['sent polarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['sent polarity'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.059047928320982"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['sent polarity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['sent polarity'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>doc_type</th>\n",
       "      <th>resp_to</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sent polarity</th>\n",
       "      <th>sent subjectivity</th>\n",
       "      <th>sent label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>7d7sq8</td>\n",
       "      <td>slc_comment</td>\n",
       "      <td>Upvoting this so it gets more attention. I hop...</td>\n",
       "      <td>Thank you</td>\n",
       "      <td>2017-11-16 09:36:47</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>128</td>\n",
       "      <td>7d7sq8</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thank you</td>\n",
       "      <td>2017-11-16 09:36:47</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>166</td>\n",
       "      <td>7d7sq8</td>\n",
       "      <td>slc_comment</td>\n",
       "      <td>Thanks - got wind of the situation this mornin...</td>\n",
       "      <td>ENABLE MULTI-FACTOR AUTHENTICATION PLEASE.</td>\n",
       "      <td>2017-11-16 18:17:31</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>180</td>\n",
       "      <td>7d7sq8</td>\n",
       "      <td>slc_comment</td>\n",
       "      <td>Because it can generally mean \"departing\" whic...</td>\n",
       "      <td>### EXODUS 20:15 \"**THOU SHALT NOT STEAL**\"</td>\n",
       "      <td>2017-11-16 20:46:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>187</td>\n",
       "      <td>7d7sq8</td>\n",
       "      <td>slc_comment</td>\n",
       "      <td>you mentioned you took a shower. anyone in the...</td>\n",
       "      <td>No haha</td>\n",
       "      <td>2017-11-16 06:48:36</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>250</td>\n",
       "      <td>7d7sq8</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ENABLE MULTI-FACTOR AUTHENTICATION PLEASE.</td>\n",
       "      <td>2017-11-16 18:17:31</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>262</td>\n",
       "      <td>7d7sq8</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>### EXODUS 20:15 \"**THOU SHALT NOT STEAL**\"</td>\n",
       "      <td>2017-11-16 20:46:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>266</td>\n",
       "      <td>7d7sq8</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No haha</td>\n",
       "      <td>2017-11-16 06:48:36</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>267</td>\n",
       "      <td>7d7sq8</td>\n",
       "      <td>slc_comment</td>\n",
       "      <td>No haha</td>\n",
       "      <td>Xanax?</td>\n",
       "      <td>2017-11-16 07:08:05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>324</td>\n",
       "      <td>7d7sq8</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Xanax?</td>\n",
       "      <td>2017-11-16 07:08:05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>705</td>\n",
       "      <td>7d4bm2</td>\n",
       "      <td>slc_comment</td>\n",
       "      <td>Will do!</td>\n",
       "      <td>So... ? ^^</td>\n",
       "      <td>2017-11-16 22:47:30</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>711</td>\n",
       "      <td>7d4bm2</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So... ? ^^</td>\n",
       "      <td>2017-11-16 22:47:30</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>973</td>\n",
       "      <td>7d2onr</td>\n",
       "      <td>slc_comment</td>\n",
       "      <td>I like the idea</td>\n",
       "      <td>Thanks!</td>\n",
       "      <td>2017-11-15 11:31:08</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>978</td>\n",
       "      <td>7d2onr</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thanks!</td>\n",
       "      <td>2017-11-15 11:31:08</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>1095</td>\n",
       "      <td>7d1g5v</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fghfgh\\n</td>\n",
       "      <td>2017-11-16 05:39:04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>1169</td>\n",
       "      <td>7d1g5v</td>\n",
       "      <td>slc_comment</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>:)</td>\n",
       "      <td>2017-11-16 20:16:10</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>1178</td>\n",
       "      <td>7d1g5v</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:)</td>\n",
       "      <td>2017-11-16 20:16:10</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>1271</td>\n",
       "      <td>7d0pbn</td>\n",
       "      <td>slc_comment</td>\n",
       "      <td>Hello! Right, so, let me clarify a few things....</td>\n",
       "      <td># IT WAS JUST A PRANK, BRO!</td>\n",
       "      <td>2017-11-15 21:18:45</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>1293</td>\n",
       "      <td>7d0pbn</td>\n",
       "      <td>slc_comment</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>?</td>\n",
       "      <td>2017-11-15 07:54:08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>1336</td>\n",
       "      <td>7d0pbn</td>\n",
       "      <td>slc_comment</td>\n",
       "      <td>Welp.\\n\\nAt least this took attention away fro...</td>\n",
       "      <td>Hahahahahhaa</td>\n",
       "      <td>2017-11-15 15:23:56</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>1390</td>\n",
       "      <td>7d0pbn</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td># IT WAS JUST A PRANK, BRO!</td>\n",
       "      <td>2017-11-15 21:18:45</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>1403</td>\n",
       "      <td>7d0pbn</td>\n",
       "      <td>slc_comment</td>\n",
       "      <td>Tankies. Definitely tankies.</td>\n",
       "      <td>:(</td>\n",
       "      <td>2017-11-15 19:49:39</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>1410</td>\n",
       "      <td>7d0pbn</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>?</td>\n",
       "      <td>2017-11-15 07:54:08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>1440</td>\n",
       "      <td>7d0pbn</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hahahahahhaa</td>\n",
       "      <td>2017-11-15 15:23:56</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>1497</td>\n",
       "      <td>7d0pbn</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:(</td>\n",
       "      <td>2017-11-15 19:49:39</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>1527</td>\n",
       "      <td>7d0pbn</td>\n",
       "      <td>slc_comment</td>\n",
       "      <td>Trolling is inherently childish. But we grew u...</td>\n",
       "      <td>Hahahahahahaahaha</td>\n",
       "      <td>2017-11-15 15:24:29</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>1577</td>\n",
       "      <td>7d0pbn</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hahahahahahaahaha</td>\n",
       "      <td>2017-11-15 15:24:29</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709</th>\n",
       "      <td>1709</td>\n",
       "      <td>7d0pbn</td>\n",
       "      <td>slc_comment</td>\n",
       "      <td>This is a nuanced debate. Thank you.</td>\n",
       "      <td>:)</td>\n",
       "      <td>2017-11-15 19:51:15</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1715</th>\n",
       "      <td>1715</td>\n",
       "      <td>7d0pbn</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:)</td>\n",
       "      <td>2017-11-15 19:51:15</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>107</td>\n",
       "      <td>7de0rf</td>\n",
       "      <td>slc_comment</td>\n",
       "      <td>Still a year away from that being a viable option</td>\n",
       "      <td>Ah ok. Thanks!</td>\n",
       "      <td>2017-11-16 21:23:37</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166949</th>\n",
       "      <td>245</td>\n",
       "      <td>85luvr</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>+1</td>\n",
       "      <td>2018-03-20 00:38:19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167043</th>\n",
       "      <td>339</td>\n",
       "      <td>85k24e</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GRID+</td>\n",
       "      <td>2018-03-20 22:28:31</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167128</th>\n",
       "      <td>424</td>\n",
       "      <td>85ingu</td>\n",
       "      <td>post</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BITNATION</td>\n",
       "      <td>2018-03-19 15:07:46</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167168</th>\n",
       "      <td>464</td>\n",
       "      <td>85hncy</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hohohoüëèüëèüëè</td>\n",
       "      <td>2018-03-19 13:48:19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167363</th>\n",
       "      <td>659</td>\n",
       "      <td>85fcg1</td>\n",
       "      <td>slc_comment</td>\n",
       "      <td>I appreciate you telling me. But my issue is s...</td>\n",
       "      <td>Smh</td>\n",
       "      <td>2018-03-19 21:57:11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167364</th>\n",
       "      <td>660</td>\n",
       "      <td>85fcg1</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Smh</td>\n",
       "      <td>2018-03-19 21:57:11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167408</th>\n",
       "      <td>43</td>\n",
       "      <td>85wajh</td>\n",
       "      <td>slc_comment</td>\n",
       "      <td>To the moon???</td>\n",
       "      <td>Too soon.</td>\n",
       "      <td>2018-03-21 05:32:47</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167416</th>\n",
       "      <td>51</td>\n",
       "      <td>85wajh</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FUCK I THOT THEY WERE GONA USE RIPPLE\\nFUCK ME...</td>\n",
       "      <td>2018-03-21 04:00:51</td>\n",
       "      <td>0.636111</td>\n",
       "      <td>0.636111</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167417</th>\n",
       "      <td>52</td>\n",
       "      <td>85wajh</td>\n",
       "      <td>slc_comment</td>\n",
       "      <td>FUCK I THOT THEY WERE GONA USE RIPPLE\\nFUCK ME...</td>\n",
       "      <td>FUCK I THOUGHT BITCONNECT</td>\n",
       "      <td>2018-03-21 04:03:42</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167424</th>\n",
       "      <td>59</td>\n",
       "      <td>85wajh</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hahahahahhahahahahahahahahahhahahahahahahahaha...</td>\n",
       "      <td>2018-03-21 21:26:36</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167429</th>\n",
       "      <td>64</td>\n",
       "      <td>85wajh</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Too soon.</td>\n",
       "      <td>2018-03-21 05:32:47</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167432</th>\n",
       "      <td>67</td>\n",
       "      <td>85wajh</td>\n",
       "      <td>slc_comment</td>\n",
       "      <td>Moon isn't interesting to NASA anymore. I beli...</td>\n",
       "      <td>Rarri's on mars</td>\n",
       "      <td>2018-03-21 08:45:10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167441</th>\n",
       "      <td>76</td>\n",
       "      <td>85wajh</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FUCK I THOUGHT BITCONNECT</td>\n",
       "      <td>2018-03-21 04:03:42</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167442</th>\n",
       "      <td>77</td>\n",
       "      <td>85wajh</td>\n",
       "      <td>slc_comment</td>\n",
       "      <td>FUCK I THOUGHT BITCONNECT</td>\n",
       "      <td>BEET-CON-EHHHHHHHHHHH-CT!!! WOOOOOOO</td>\n",
       "      <td>2018-03-21 16:56:29</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167443</th>\n",
       "      <td>78</td>\n",
       "      <td>85wajh</td>\n",
       "      <td>slc_comment</td>\n",
       "      <td>FUCK I THOUGHT BITCONNECT</td>\n",
       "      <td>FUCK I THOT THEY USE DAVOSCOIN</td>\n",
       "      <td>2018-03-21 18:13:31</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167448</th>\n",
       "      <td>83</td>\n",
       "      <td>85wajh</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rarri's on mars</td>\n",
       "      <td>2018-03-21 08:45:10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167459</th>\n",
       "      <td>94</td>\n",
       "      <td>85wajh</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BEET-CON-EHHHHHHHHHHH-CT!!! WOOOOOOO</td>\n",
       "      <td>2018-03-21 16:56:29</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167460</th>\n",
       "      <td>95</td>\n",
       "      <td>85wajh</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FUCK I THOT THEY USE DAVOSCOIN</td>\n",
       "      <td>2018-03-21 18:13:31</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167475</th>\n",
       "      <td>110</td>\n",
       "      <td>85w6et</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thank you guys!</td>\n",
       "      <td>2018-03-21 11:15:52</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167612</th>\n",
       "      <td>247</td>\n",
       "      <td>85tthv</td>\n",
       "      <td>slc_comment</td>\n",
       "      <td>I'm going to be honest with you guys. Your ave...</td>\n",
       "      <td>TCP/IP much? ;-)</td>\n",
       "      <td>2018-03-21 04:35:45</td>\n",
       "      <td>1.225000</td>\n",
       "      <td>1.225000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167620</th>\n",
       "      <td>255</td>\n",
       "      <td>85tthv</td>\n",
       "      <td>slc_comment</td>\n",
       "      <td>Clickbait title: nothing to do with Amazon doi...</td>\n",
       "      <td>Thanks !</td>\n",
       "      <td>2018-03-21 03:43:55</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167641</th>\n",
       "      <td>276</td>\n",
       "      <td>85tthv</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TCP/IP much? ;-)</td>\n",
       "      <td>2018-03-21 04:35:45</td>\n",
       "      <td>1.225000</td>\n",
       "      <td>1.225000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167650</th>\n",
       "      <td>285</td>\n",
       "      <td>85tthv</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thanks !</td>\n",
       "      <td>2018-03-21 03:43:55</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167885</th>\n",
       "      <td>41</td>\n",
       "      <td>8652kk</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No.</td>\n",
       "      <td>2018-03-22 00:14:17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167914</th>\n",
       "      <td>70</td>\n",
       "      <td>863qlf</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Akasha</td>\n",
       "      <td>2018-03-21 22:14:12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167947</th>\n",
       "      <td>103</td>\n",
       "      <td>863at0</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Looks promising.</td>\n",
       "      <td>2018-03-22 01:01:07</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168178</th>\n",
       "      <td>334</td>\n",
       "      <td>861d9s</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BUIDL</td>\n",
       "      <td>2018-03-21 21:30:41</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168185</th>\n",
       "      <td>341</td>\n",
       "      <td>861d9s</td>\n",
       "      <td>slc_comment</td>\n",
       "      <td>https://github.com/ethereum/EIPs/issues/87 thi...</td>\n",
       "      <td>Thanks!!</td>\n",
       "      <td>2018-03-21 22:39:41</td>\n",
       "      <td>1.312500</td>\n",
       "      <td>1.312500</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168187</th>\n",
       "      <td>343</td>\n",
       "      <td>861d9s</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thanks!!</td>\n",
       "      <td>2018-03-21 22:39:41</td>\n",
       "      <td>1.312500</td>\n",
       "      <td>1.312500</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168285</th>\n",
       "      <td>441</td>\n",
       "      <td>85y31t</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Why aging?</td>\n",
       "      <td>2018-03-21 05:21:47</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3398 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  doc_id     doc_type  \\\n",
       "30              30  7d7sq8  slc_comment   \n",
       "128            128  7d7sq8      comment   \n",
       "166            166  7d7sq8  slc_comment   \n",
       "180            180  7d7sq8  slc_comment   \n",
       "187            187  7d7sq8  slc_comment   \n",
       "250            250  7d7sq8      comment   \n",
       "262            262  7d7sq8      comment   \n",
       "266            266  7d7sq8      comment   \n",
       "267            267  7d7sq8  slc_comment   \n",
       "324            324  7d7sq8      comment   \n",
       "705            705  7d4bm2  slc_comment   \n",
       "711            711  7d4bm2      comment   \n",
       "973            973  7d2onr  slc_comment   \n",
       "978            978  7d2onr      comment   \n",
       "1095          1095  7d1g5v      comment   \n",
       "1169          1169  7d1g5v  slc_comment   \n",
       "1178          1178  7d1g5v      comment   \n",
       "1271          1271  7d0pbn  slc_comment   \n",
       "1293          1293  7d0pbn  slc_comment   \n",
       "1336          1336  7d0pbn  slc_comment   \n",
       "1390          1390  7d0pbn      comment   \n",
       "1403          1403  7d0pbn  slc_comment   \n",
       "1410          1410  7d0pbn      comment   \n",
       "1440          1440  7d0pbn      comment   \n",
       "1497          1497  7d0pbn      comment   \n",
       "1527          1527  7d0pbn  slc_comment   \n",
       "1577          1577  7d0pbn      comment   \n",
       "1709          1709  7d0pbn  slc_comment   \n",
       "1715          1715  7d0pbn      comment   \n",
       "2057           107  7de0rf  slc_comment   \n",
       "...            ...     ...          ...   \n",
       "166949         245  85luvr      comment   \n",
       "167043         339  85k24e      comment   \n",
       "167128         424  85ingu         post   \n",
       "167168         464  85hncy      comment   \n",
       "167363         659  85fcg1  slc_comment   \n",
       "167364         660  85fcg1      comment   \n",
       "167408          43  85wajh  slc_comment   \n",
       "167416          51  85wajh      comment   \n",
       "167417          52  85wajh  slc_comment   \n",
       "167424          59  85wajh      comment   \n",
       "167429          64  85wajh      comment   \n",
       "167432          67  85wajh  slc_comment   \n",
       "167441          76  85wajh      comment   \n",
       "167442          77  85wajh  slc_comment   \n",
       "167443          78  85wajh  slc_comment   \n",
       "167448          83  85wajh      comment   \n",
       "167459          94  85wajh      comment   \n",
       "167460          95  85wajh      comment   \n",
       "167475         110  85w6et      comment   \n",
       "167612         247  85tthv  slc_comment   \n",
       "167620         255  85tthv  slc_comment   \n",
       "167641         276  85tthv      comment   \n",
       "167650         285  85tthv      comment   \n",
       "167885          41  8652kk      comment   \n",
       "167914          70  863qlf      comment   \n",
       "167947         103  863at0      comment   \n",
       "168178         334  861d9s      comment   \n",
       "168185         341  861d9s  slc_comment   \n",
       "168187         343  861d9s      comment   \n",
       "168285         441  85y31t      comment   \n",
       "\n",
       "                                                  resp_to  \\\n",
       "30      Upvoting this so it gets more attention. I hop...   \n",
       "128                                                   NaN   \n",
       "166     Thanks - got wind of the situation this mornin...   \n",
       "180     Because it can generally mean \"departing\" whic...   \n",
       "187     you mentioned you took a shower. anyone in the...   \n",
       "250                                                   NaN   \n",
       "262                                                   NaN   \n",
       "266                                                   NaN   \n",
       "267                                              No haha    \n",
       "324                                                   NaN   \n",
       "705                                             Will do!    \n",
       "711                                                   NaN   \n",
       "973                                       I like the idea   \n",
       "978                                                   NaN   \n",
       "1095                                                  NaN   \n",
       "1169                                            [deleted]   \n",
       "1178                                                  NaN   \n",
       "1271    Hello! Right, so, let me clarify a few things....   \n",
       "1293                                            [deleted]   \n",
       "1336    Welp.\\n\\nAt least this took attention away fro...   \n",
       "1390                                                  NaN   \n",
       "1403                         Tankies. Definitely tankies.   \n",
       "1410                                                  NaN   \n",
       "1440                                                  NaN   \n",
       "1497                                                  NaN   \n",
       "1527    Trolling is inherently childish. But we grew u...   \n",
       "1577                                                  NaN   \n",
       "1709                 This is a nuanced debate. Thank you.   \n",
       "1715                                                  NaN   \n",
       "2057    Still a year away from that being a viable option   \n",
       "...                                                   ...   \n",
       "166949                                                NaN   \n",
       "167043                                                NaN   \n",
       "167128                                                NaN   \n",
       "167168                                                NaN   \n",
       "167363  I appreciate you telling me. But my issue is s...   \n",
       "167364                                                NaN   \n",
       "167408                                     To the moon???   \n",
       "167416                                                NaN   \n",
       "167417  FUCK I THOT THEY WERE GONA USE RIPPLE\\nFUCK ME...   \n",
       "167424                                                NaN   \n",
       "167429                                                NaN   \n",
       "167432  Moon isn't interesting to NASA anymore. I beli...   \n",
       "167441                                                NaN   \n",
       "167442                          FUCK I THOUGHT BITCONNECT   \n",
       "167443                          FUCK I THOUGHT BITCONNECT   \n",
       "167448                                                NaN   \n",
       "167459                                                NaN   \n",
       "167460                                                NaN   \n",
       "167475                                                NaN   \n",
       "167612  I'm going to be honest with you guys. Your ave...   \n",
       "167620  Clickbait title: nothing to do with Amazon doi...   \n",
       "167641                                                NaN   \n",
       "167650                                                NaN   \n",
       "167885                                                NaN   \n",
       "167914                                                NaN   \n",
       "167947                                                NaN   \n",
       "168178                                                NaN   \n",
       "168185  https://github.com/ethereum/EIPs/issues/87 thi...   \n",
       "168187                                                NaN   \n",
       "168285                                                NaN   \n",
       "\n",
       "                                                     text           timestamp  \\\n",
       "30                                              Thank you 2017-11-16 09:36:47   \n",
       "128                                             Thank you 2017-11-16 09:36:47   \n",
       "166            ENABLE MULTI-FACTOR AUTHENTICATION PLEASE. 2017-11-16 18:17:31   \n",
       "180           ### EXODUS 20:15 \"**THOU SHALT NOT STEAL**\" 2017-11-16 20:46:00   \n",
       "187                                              No haha  2017-11-16 06:48:36   \n",
       "250            ENABLE MULTI-FACTOR AUTHENTICATION PLEASE. 2017-11-16 18:17:31   \n",
       "262           ### EXODUS 20:15 \"**THOU SHALT NOT STEAL**\" 2017-11-16 20:46:00   \n",
       "266                                              No haha  2017-11-16 06:48:36   \n",
       "267                                                Xanax? 2017-11-16 07:08:05   \n",
       "324                                                Xanax? 2017-11-16 07:08:05   \n",
       "705                                            So... ? ^^ 2017-11-16 22:47:30   \n",
       "711                                            So... ? ^^ 2017-11-16 22:47:30   \n",
       "973                                              Thanks!  2017-11-15 11:31:08   \n",
       "978                                              Thanks!  2017-11-15 11:31:08   \n",
       "1095                                             fghfgh\\n 2017-11-16 05:39:04   \n",
       "1169                                                   :) 2017-11-16 20:16:10   \n",
       "1178                                                   :) 2017-11-16 20:16:10   \n",
       "1271                          # IT WAS JUST A PRANK, BRO! 2017-11-15 21:18:45   \n",
       "1293                                                    ? 2017-11-15 07:54:08   \n",
       "1336                                         Hahahahahhaa 2017-11-15 15:23:56   \n",
       "1390                          # IT WAS JUST A PRANK, BRO! 2017-11-15 21:18:45   \n",
       "1403                                                   :( 2017-11-15 19:49:39   \n",
       "1410                                                    ? 2017-11-15 07:54:08   \n",
       "1440                                         Hahahahahhaa 2017-11-15 15:23:56   \n",
       "1497                                                   :( 2017-11-15 19:49:39   \n",
       "1527                                   Hahahahahahaahaha  2017-11-15 15:24:29   \n",
       "1577                                   Hahahahahahaahaha  2017-11-15 15:24:29   \n",
       "1709                                                   :) 2017-11-15 19:51:15   \n",
       "1715                                                   :) 2017-11-15 19:51:15   \n",
       "2057                                       Ah ok. Thanks! 2017-11-16 21:23:37   \n",
       "...                                                   ...                 ...   \n",
       "166949                                                +1  2018-03-20 00:38:19   \n",
       "167043                                              GRID+ 2018-03-20 22:28:31   \n",
       "167128                                         BITNATION  2018-03-19 15:07:46   \n",
       "167168                                          Hohohoüëèüëèüëè 2018-03-19 13:48:19   \n",
       "167363                                                Smh 2018-03-19 21:57:11   \n",
       "167364                                                Smh 2018-03-19 21:57:11   \n",
       "167408                                          Too soon. 2018-03-21 05:32:47   \n",
       "167416  FUCK I THOT THEY WERE GONA USE RIPPLE\\nFUCK ME... 2018-03-21 04:00:51   \n",
       "167417                          FUCK I THOUGHT BITCONNECT 2018-03-21 04:03:42   \n",
       "167424  Hahahahahhahahahahahahahahahhahahahahahahahaha... 2018-03-21 21:26:36   \n",
       "167429                                          Too soon. 2018-03-21 05:32:47   \n",
       "167432                                   Rarri's on mars  2018-03-21 08:45:10   \n",
       "167441                          FUCK I THOUGHT BITCONNECT 2018-03-21 04:03:42   \n",
       "167442               BEET-CON-EHHHHHHHHHHH-CT!!! WOOOOOOO 2018-03-21 16:56:29   \n",
       "167443                     FUCK I THOT THEY USE DAVOSCOIN 2018-03-21 18:13:31   \n",
       "167448                                   Rarri's on mars  2018-03-21 08:45:10   \n",
       "167459               BEET-CON-EHHHHHHHHHHH-CT!!! WOOOOOOO 2018-03-21 16:56:29   \n",
       "167460                     FUCK I THOT THEY USE DAVOSCOIN 2018-03-21 18:13:31   \n",
       "167475                                    Thank you guys! 2018-03-21 11:15:52   \n",
       "167612                                   TCP/IP much? ;-) 2018-03-21 04:35:45   \n",
       "167620                                           Thanks ! 2018-03-21 03:43:55   \n",
       "167641                                   TCP/IP much? ;-) 2018-03-21 04:35:45   \n",
       "167650                                           Thanks ! 2018-03-21 03:43:55   \n",
       "167885                                                No. 2018-03-22 00:14:17   \n",
       "167914                                             Akasha 2018-03-21 22:14:12   \n",
       "167947                                   Looks promising. 2018-03-22 01:01:07   \n",
       "168178                                              BUIDL 2018-03-21 21:30:41   \n",
       "168185                                           Thanks!! 2018-03-21 22:39:41   \n",
       "168187                                           Thanks!! 2018-03-21 22:39:41   \n",
       "168285                                         Why aging? 2018-03-21 05:21:47   \n",
       "\n",
       "        sent polarity  sent subjectivity sent label  \n",
       "30           1.000000           1.000000        neg  \n",
       "128          1.000000           1.000000        neg  \n",
       "166          1.000000           1.000000        neg  \n",
       "180          1.000000           1.000000        neg  \n",
       "187          0.900000           0.900000        neg  \n",
       "250          1.000000           1.000000        neg  \n",
       "262          1.000000           1.000000        neg  \n",
       "266          0.900000           0.900000        neg  \n",
       "267          1.000000           1.000000        neg  \n",
       "324          1.000000           1.000000        neg  \n",
       "705          1.000000           1.000000        neg  \n",
       "711          1.000000           1.000000        neg  \n",
       "973          1.250000           1.250000        pos  \n",
       "978          1.250000           1.250000        pos  \n",
       "1095         1.000000           1.000000        neg  \n",
       "1169         1.500000           1.500000        pos  \n",
       "1178         1.500000           1.500000        pos  \n",
       "1271         1.000000           1.000000        neg  \n",
       "1293         1.000000           1.000000        neg  \n",
       "1336         1.000000           1.000000        neg  \n",
       "1390         1.000000           1.000000        neg  \n",
       "1403         0.250000           0.250000        neg  \n",
       "1410         1.000000           1.000000        neg  \n",
       "1440         1.000000           1.000000        neg  \n",
       "1497         0.250000           0.250000        neg  \n",
       "1527         1.000000           1.000000        neg  \n",
       "1577         1.000000           1.000000        neg  \n",
       "1709         1.500000           1.500000        pos  \n",
       "1715         1.500000           1.500000        pos  \n",
       "2057         1.375000           1.375000        pos  \n",
       "...               ...                ...        ...  \n",
       "166949       1.000000           1.000000        neg  \n",
       "167043       1.000000           1.000000        neg  \n",
       "167128       1.000000           1.000000        neg  \n",
       "167168       1.000000           1.000000        neg  \n",
       "167363       1.000000           1.000000        neg  \n",
       "167364       1.000000           1.000000        neg  \n",
       "167408       1.000000           1.000000        neg  \n",
       "167416       0.636111           0.636111        neg  \n",
       "167417       0.600000           0.600000        neg  \n",
       "167424       1.000000           1.000000        neg  \n",
       "167429       1.000000           1.000000        neg  \n",
       "167432       1.000000           1.000000        neg  \n",
       "167441       0.600000           0.600000        neg  \n",
       "167442       1.000000           1.000000        neg  \n",
       "167443       0.600000           0.600000        neg  \n",
       "167448       1.000000           1.000000        neg  \n",
       "167459       1.000000           1.000000        neg  \n",
       "167460       0.600000           0.600000        neg  \n",
       "167475       1.000000           1.000000        neg  \n",
       "167612       1.225000           1.225000        pos  \n",
       "167620       1.250000           1.250000        pos  \n",
       "167641       1.225000           1.225000        pos  \n",
       "167650       1.250000           1.250000        pos  \n",
       "167885       1.000000           1.000000        neg  \n",
       "167914       1.000000           1.000000        neg  \n",
       "167947       1.200000           1.200000        pos  \n",
       "168178       1.000000           1.000000        neg  \n",
       "168185       1.312500           1.312500        pos  \n",
       "168187       1.312500           1.312500        pos  \n",
       "168285       1.000000           1.000000        neg  \n",
       "\n",
       "[3398 rows x 9 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = df2.set_index(df2['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_mean = df2.groupby(df2['timestamp'].dt.normalize()).mean() #.dt.normalize()) hmmmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8846153846153846"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mean['sent polarity'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list1 = df_mean['sent polarity'].loc['2017-11-15':'2018-03-21']\n",
    "df_mean['sent polarity'].max()\n",
    "mean_list_norm = list1/(df_mean['sent polarity'].max())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### NOW some machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prepping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>doc_type</th>\n",
       "      <th>resp_to</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sent polarity</th>\n",
       "      <th>sent subjectivity</th>\n",
       "      <th>sent label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-16 09:36:47</th>\n",
       "      <td>30</td>\n",
       "      <td>7d7sq8</td>\n",
       "      <td>slc_comment</td>\n",
       "      <td>Upvoting this so it gets more attention. I hop...</td>\n",
       "      <td>Thank you</td>\n",
       "      <td>2017-11-16 09:36:47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-16 09:36:47</th>\n",
       "      <td>128</td>\n",
       "      <td>7d7sq8</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thank you</td>\n",
       "      <td>2017-11-16 09:36:47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-16 18:17:31</th>\n",
       "      <td>166</td>\n",
       "      <td>7d7sq8</td>\n",
       "      <td>slc_comment</td>\n",
       "      <td>Thanks - got wind of the situation this mornin...</td>\n",
       "      <td>ENABLE MULTI-FACTOR AUTHENTICATION PLEASE.</td>\n",
       "      <td>2017-11-16 18:17:31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-16 20:46:00</th>\n",
       "      <td>180</td>\n",
       "      <td>7d7sq8</td>\n",
       "      <td>slc_comment</td>\n",
       "      <td>Because it can generally mean \"departing\" whic...</td>\n",
       "      <td>### EXODUS 20:15 \"**THOU SHALT NOT STEAL**\"</td>\n",
       "      <td>2017-11-16 20:46:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-16 06:48:36</th>\n",
       "      <td>187</td>\n",
       "      <td>7d7sq8</td>\n",
       "      <td>slc_comment</td>\n",
       "      <td>you mentioned you took a shower. anyone in the...</td>\n",
       "      <td>No haha</td>\n",
       "      <td>2017-11-16 06:48:36</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Unnamed: 0  doc_id     doc_type  \\\n",
       "timestamp                                              \n",
       "2017-11-16 09:36:47          30  7d7sq8  slc_comment   \n",
       "2017-11-16 09:36:47         128  7d7sq8      comment   \n",
       "2017-11-16 18:17:31         166  7d7sq8  slc_comment   \n",
       "2017-11-16 20:46:00         180  7d7sq8  slc_comment   \n",
       "2017-11-16 06:48:36         187  7d7sq8  slc_comment   \n",
       "\n",
       "                                                               resp_to  \\\n",
       "timestamp                                                                \n",
       "2017-11-16 09:36:47  Upvoting this so it gets more attention. I hop...   \n",
       "2017-11-16 09:36:47                                                NaN   \n",
       "2017-11-16 18:17:31  Thanks - got wind of the situation this mornin...   \n",
       "2017-11-16 20:46:00  Because it can generally mean \"departing\" whic...   \n",
       "2017-11-16 06:48:36  you mentioned you took a shower. anyone in the...   \n",
       "\n",
       "                                                            text  \\\n",
       "timestamp                                                          \n",
       "2017-11-16 09:36:47                                    Thank you   \n",
       "2017-11-16 09:36:47                                    Thank you   \n",
       "2017-11-16 18:17:31   ENABLE MULTI-FACTOR AUTHENTICATION PLEASE.   \n",
       "2017-11-16 20:46:00  ### EXODUS 20:15 \"**THOU SHALT NOT STEAL**\"   \n",
       "2017-11-16 06:48:36                                     No haha    \n",
       "\n",
       "                              timestamp  sent polarity  sent subjectivity  \\\n",
       "timestamp                                                                   \n",
       "2017-11-16 09:36:47 2017-11-16 09:36:47            1.0                1.0   \n",
       "2017-11-16 09:36:47 2017-11-16 09:36:47            1.0                1.0   \n",
       "2017-11-16 18:17:31 2017-11-16 18:17:31            1.0                1.0   \n",
       "2017-11-16 20:46:00 2017-11-16 20:46:00            1.0                1.0   \n",
       "2017-11-16 06:48:36 2017-11-16 06:48:36            0.9                0.9   \n",
       "\n",
       "                    sent label  \n",
       "timestamp                       \n",
       "2017-11-16 09:36:47        neg  \n",
       "2017-11-16 09:36:47        neg  \n",
       "2017-11-16 18:17:31        neg  \n",
       "2017-11-16 20:46:00        neg  \n",
       "2017-11-16 06:48:36        neg  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Alexandra/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "import text_normalizer as tn\n",
    "from contractions import CONTRACTION_MAP #had to configure contraction map and had to download english module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Alexandra/anaconda/lib/python3.6/site-packages/bs4/__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "/Users/Alexandra/anaconda/lib/python3.6/site-packages/bs4/__init__.py:219: UserWarning: \"b'..'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    }
   ],
   "source": [
    "# take a peek at the data\n",
    "#print(df2.head())\n",
    "reviews = np.array(df2['text'])\n",
    "sentiments = np.array(df2['sent label'])\n",
    "\n",
    "# build train and test datasets\n",
    "train_reviews = reviews[:1699]\n",
    "train_sentiments = sentiments[:1699]\n",
    "test_reviews = reviews[1699:]\n",
    "test_sentiments = sentiments[1699:]\n",
    "\n",
    "# normalize datasets\n",
    "norm_train_reviews = tn.normalize_corpus(train_reviews)\n",
    "norm_test_reviews = tn.normalize_corpus(test_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Alexandra/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# build BOW features on train reviews\n",
    "cv = CountVectorizer(binary=False, min_df=0.0, max_df=1.0, ngram_range=(1,2))\n",
    "cv_train_features = cv.fit_transform(norm_train_reviews)\n",
    "# build TFIDF features on train reviews\n",
    "tv = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0, ngram_range=(1,2),\n",
    "                     sublinear_tf=True)\n",
    "tv_train_features = tv.fit_transform(norm_train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Alexandra/anaconda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    }
   ],
   "source": [
    "# transform test reviews into features\n",
    "cv_test_features = cv.transform(norm_test_reviews)\n",
    "tv_test_features = tv.transform(norm_test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW model:> Train features shape: (1699, 903)  Test features shape: (1699, 903)\n",
      "TFIDF model:> Train features shape: (1699, 903)  Test features shape: (1699, 903)\n"
     ]
    }
   ],
   "source": [
    "print('BOW model:> Train features shape:', cv_train_features.shape, ' Test features shape:', cv_test_features.shape)\n",
    "print('TFIDF model:> Train features shape:', tv_train_features.shape, ' Test features shape:', tv_test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import model_evaluation_utils as meu\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', max_iter=100, C=1)\n",
    "svm = SGDClassifier(loss='hinge', n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance metrics:\n",
      "------------------------------\n",
      "Accuracy: 0.9105\n",
      "Precision: 0.907\n",
      "Recall: 0.9105\n",
      "F1 Score: 0.9065\n",
      "\n",
      "Model Classification report:\n",
      "------------------------------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        pos       0.83      0.66      0.74       323\n",
      "        neg       0.92      0.97      0.95      1376\n",
      "\n",
      "avg / total       0.91      0.91      0.91      1699\n",
      "\n",
      "\n",
      "Prediction Confusion Matrix:\n",
      "------------------------------\n",
      "            Predicted:      \n",
      "                   pos   neg\n",
      "Actual: pos        214   109\n",
      "        neg         43  1333\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression model on BOW features\n",
    "lr_bow_predictions = meu.train_predict_model(classifier=lr, \n",
    "                                             train_features=cv_train_features, train_labels=train_sentiments,\n",
    "                                             test_features=cv_test_features, test_labels=test_sentiments)\n",
    "meu.display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=lr_bow_predictions,\n",
    "                                      classes=['pos', 'neg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newer supervised deep learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Alexandra/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import gensim\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Activation, Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#import requirements\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "num_classes=3\n",
    "# tokenize train reviews & encode train labels\n",
    "tokenized_train = [tn.tokenizer.tokenize(text)\n",
    "                   for text in norm_train_reviews]\n",
    "y_tr = le.fit_transform(train_sentiments)\n",
    "y_train = keras.utils.to_categorical(y_tr, num_classes)\n",
    "# tokenize test reviews & encode test labels\n",
    "tokenized_test = [tn.tokenizer.tokenize(text)\n",
    "                   for text in norm_test_reviews]\n",
    "y_ts = le.fit_transform(test_sentiments)\n",
    "y_test = keras.utils.to_categorical(y_ts, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment class label map: {'neg': 0, 'pos': 1}\n",
      "Sample test label transformation:\n",
      "----------------------------------- \n",
      "Actual Labels: ['pos' 'pos' 'pos'] \n",
      "Encoded Labels: [1 1 1] \n",
      "One hot encoded Labels:\n",
      " [[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# print class label encoding map and encoded labels\n",
    "print('Sentiment class label map:', dict(zip(le.classes_, le.transform(le.classes_))))\n",
    "print('Sample test label transformation:\\n'+'-'*35,\n",
    "      '\\nActual Labels:', test_sentiments[:3], '\\nEncoded Labels:', y_ts[:3], \n",
    "      '\\nOne hot encoded Labels:\\n', y_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build word2vec model\n",
    "w2v_num_features = 500\n",
    "w2v_model = gensim.models.Word2Vec(tokenized_train, size=w2v_num_features, window=150,\n",
    "                                   min_count=10, sample=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def averaged_word2vec_vectorizer(corpus, model, num_features):\n",
    "    vocabulary = set(model.wv.index2word)\n",
    "    \n",
    "    def average_word_vectors(words, model, vocabulary, num_features):\n",
    "        feature_vector = np.zeros((num_features,), dtype=\"float64\")\n",
    "        nwords = 0.\n",
    "        \n",
    "        for word in words:\n",
    "            if word in vocabulary: \n",
    "                nwords = nwords + 1.\n",
    "                feature_vector = np.add(feature_vector, model[word])\n",
    "        if nwords:\n",
    "            feature_vector = np.divide(feature_vector, nwords)\n",
    "\n",
    "        return feature_vector\n",
    "\n",
    "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
    "                    for tokenized_sentence in corpus]\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Alexandra/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# generate averaged word vector features from word2vec model\n",
    "avg_wv_train_features = averaged_word2vec_vectorizer(corpus=tokenized_train, model=w2v_model,\n",
    "                                                     num_features=500)\n",
    "avg_wv_test_features = averaged_word2vec_vectorizer(corpus=tokenized_test, model=w2v_model,\n",
    "                                                    num_features=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# feature engineering with GloVe model\n",
    "train_nlp = [tn.nlp(item) for item in norm_train_reviews]\n",
    "train_glove_features = np.array([item.vector for item in train_nlp])\n",
    "\n",
    "test_nlp = [tn.nlp(item) for item in norm_test_reviews]\n",
    "test_glove_features = np.array([item.vector for item in test_nlp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec model:> Train features shape: (1699, 500)  Test features shape: (1699, 500)\n",
      "GloVe model:> Train features shape: (1699,)  Test features shape: (1699,)\n"
     ]
    }
   ],
   "source": [
    "print('Word2Vec model:> Train features shape:', avg_wv_train_features.shape, ' Test features shape:', avg_wv_test_features.shape)\n",
    "print('GloVe model:> Train features shape:', train_glove_features.shape, ' Test features shape:', test_glove_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deep nn modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "def construct_deepnn_architecture(num_input_features):\n",
    "    dnn_model = Sequential()\n",
    "    dnn_model.add(Dense(512, activation='relu', input_shape=(num_input_features,)))\n",
    "    dnn_model.add(Dropout(0.2))\n",
    "    dnn_model.add(Dense(512, activation='relu'))\n",
    "    dnn_model.add(Dropout(0.2))\n",
    "    dnn_model.add(Dense(512, activation='relu'))\n",
    "    dnn_model.add(Dropout(0.2))\n",
    "    dnn_model.add(Dense(2,activation='softmax')) #SPMETHING WITH THIS LINE!!!\n",
    "\n",
    "\n",
    "    dnn_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',                 \n",
    "                      metrics=['accuracy'])\n",
    "    return dnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/keras-team/keras/issues/7339 this has a good resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_dnn = construct_deepnn_architecture(num_input_features=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### can't do the visualizations sample deep architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"665pt\" viewBox=\"0.00 0.00 225.51 664.80\" width=\"226pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 660.8)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-660.8 221.5078,-660.8 221.5078,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 5183084136 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>5183084136</title>\n",
       "<polygon fill=\"none\" points=\"0,-606.7 0,-656.3 217.5078,-656.3 217.5078,-606.7 0,-606.7\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"39.0968\" y=\"-627.3\">InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"78.1936,-606.7 78.1936,-656.3 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"106.0295\" y=\"-639.7\">input:</text>\n",
       "<polyline fill=\"none\" points=\"78.1936,-631.5 133.8654,-631.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"106.0295\" y=\"-614.9\">output:</text>\n",
       "<polyline fill=\"none\" points=\"133.8654,-606.7 133.8654,-656.3 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"175.6866\" y=\"-639.7\">(None, 500)</text>\n",
       "<polyline fill=\"none\" points=\"133.8654,-631.5 217.5078,-631.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"175.6866\" y=\"-614.9\">(None, 500)</text>\n",
       "</g>\n",
       "<!-- 5183048840 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>5183048840</title>\n",
       "<polygon fill=\"none\" points=\"13.6066,-520.1 13.6066,-569.7 203.9012,-569.7 203.9012,-520.1 13.6066,-520.1\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"39.0968\" y=\"-540.7\">Dense</text>\n",
       "<polyline fill=\"none\" points=\"64.587,-520.1 64.587,-569.7 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"92.4229\" y=\"-553.1\">input:</text>\n",
       "<polyline fill=\"none\" points=\"64.587,-544.9 120.2588,-544.9 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"92.4229\" y=\"-528.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"120.2588,-520.1 120.2588,-569.7 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162.08\" y=\"-553.1\">(None, 500)</text>\n",
       "<polyline fill=\"none\" points=\"120.2588,-544.9 203.9012,-544.9 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162.08\" y=\"-528.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 5183084136&#45;&gt;5183048840 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>5183084136-&gt;5183048840</title>\n",
       "<path d=\"M108.7539,-606.4517C108.7539,-598.1937 108.7539,-588.8517 108.7539,-579.9864\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"112.254,-579.892 108.7539,-569.892 105.254,-579.892 112.254,-579.892\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5183099288 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>5183099288</title>\n",
       "<polygon fill=\"none\" points=\"7.7679,-433.5 7.7679,-483.1 209.7399,-483.1 209.7399,-433.5 7.7679,-433.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"39.0968\" y=\"-454.1\">Dropout</text>\n",
       "<polyline fill=\"none\" points=\"70.4257,-433.5 70.4257,-483.1 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.2616\" y=\"-466.5\">input:</text>\n",
       "<polyline fill=\"none\" points=\"70.4257,-458.3 126.0975,-458.3 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.2616\" y=\"-441.7\">output:</text>\n",
       "<polyline fill=\"none\" points=\"126.0975,-433.5 126.0975,-483.1 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"167.9187\" y=\"-466.5\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"126.0975,-458.3 209.7399,-458.3 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"167.9187\" y=\"-441.7\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 5183048840&#45;&gt;5183099288 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>5183048840-&gt;5183099288</title>\n",
       "<path d=\"M108.7539,-519.8517C108.7539,-511.5937 108.7539,-502.2517 108.7539,-493.3864\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"112.254,-493.292 108.7539,-483.292 105.254,-493.292 112.254,-493.292\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5183100240 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>5183100240</title>\n",
       "<polygon fill=\"none\" points=\"13.6066,-346.9 13.6066,-396.5 203.9012,-396.5 203.9012,-346.9 13.6066,-346.9\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"39.0968\" y=\"-367.5\">Dense</text>\n",
       "<polyline fill=\"none\" points=\"64.587,-346.9 64.587,-396.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"92.4229\" y=\"-379.9\">input:</text>\n",
       "<polyline fill=\"none\" points=\"64.587,-371.7 120.2588,-371.7 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"92.4229\" y=\"-355.1\">output:</text>\n",
       "<polyline fill=\"none\" points=\"120.2588,-346.9 120.2588,-396.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162.08\" y=\"-379.9\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"120.2588,-371.7 203.9012,-371.7 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162.08\" y=\"-355.1\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 5183099288&#45;&gt;5183100240 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>5183099288-&gt;5183100240</title>\n",
       "<path d=\"M108.7539,-433.2517C108.7539,-424.9937 108.7539,-415.6517 108.7539,-406.7864\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"112.254,-406.692 108.7539,-396.692 105.254,-406.692 112.254,-406.692\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5183046040 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>5183046040</title>\n",
       "<polygon fill=\"none\" points=\"7.7679,-260.3 7.7679,-309.9 209.7399,-309.9 209.7399,-260.3 7.7679,-260.3\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"39.0968\" y=\"-280.9\">Dropout</text>\n",
       "<polyline fill=\"none\" points=\"70.4257,-260.3 70.4257,-309.9 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.2616\" y=\"-293.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"70.4257,-285.1 126.0975,-285.1 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.2616\" y=\"-268.5\">output:</text>\n",
       "<polyline fill=\"none\" points=\"126.0975,-260.3 126.0975,-309.9 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"167.9187\" y=\"-293.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"126.0975,-285.1 209.7399,-285.1 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"167.9187\" y=\"-268.5\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 5183100240&#45;&gt;5183046040 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>5183100240-&gt;5183046040</title>\n",
       "<path d=\"M108.7539,-346.6517C108.7539,-338.3937 108.7539,-329.0517 108.7539,-320.1864\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"112.254,-320.092 108.7539,-310.092 105.254,-320.092 112.254,-320.092\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5182926920 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>5182926920</title>\n",
       "<polygon fill=\"none\" points=\"13.6066,-173.7 13.6066,-223.3 203.9012,-223.3 203.9012,-173.7 13.6066,-173.7\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"39.0968\" y=\"-194.3\">Dense</text>\n",
       "<polyline fill=\"none\" points=\"64.587,-173.7 64.587,-223.3 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"92.4229\" y=\"-206.7\">input:</text>\n",
       "<polyline fill=\"none\" points=\"64.587,-198.5 120.2588,-198.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"92.4229\" y=\"-181.9\">output:</text>\n",
       "<polyline fill=\"none\" points=\"120.2588,-173.7 120.2588,-223.3 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162.08\" y=\"-206.7\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"120.2588,-198.5 203.9012,-198.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162.08\" y=\"-181.9\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 5183046040&#45;&gt;5182926920 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>5183046040-&gt;5182926920</title>\n",
       "<path d=\"M108.7539,-260.0517C108.7539,-251.7937 108.7539,-242.4517 108.7539,-233.5864\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"112.254,-233.492 108.7539,-223.492 105.254,-233.492 112.254,-233.492\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4957863104 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>4957863104</title>\n",
       "<polygon fill=\"none\" points=\"7.7679,-87.1 7.7679,-136.7 209.7399,-136.7 209.7399,-87.1 7.7679,-87.1\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"39.0968\" y=\"-107.7\">Dropout</text>\n",
       "<polyline fill=\"none\" points=\"70.4257,-87.1 70.4257,-136.7 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.2616\" y=\"-120.1\">input:</text>\n",
       "<polyline fill=\"none\" points=\"70.4257,-111.9 126.0975,-111.9 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.2616\" y=\"-95.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"126.0975,-87.1 126.0975,-136.7 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"167.9187\" y=\"-120.1\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"126.0975,-111.9 209.7399,-111.9 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"167.9187\" y=\"-95.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 5182926920&#45;&gt;4957863104 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>5182926920-&gt;4957863104</title>\n",
       "<path d=\"M108.7539,-173.4517C108.7539,-165.1937 108.7539,-155.8517 108.7539,-146.9864\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"112.254,-146.892 108.7539,-136.892 105.254,-146.892 112.254,-146.892\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5183082848 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>5183082848</title>\n",
       "<polygon fill=\"none\" points=\"13.6066,-.5 13.6066,-50.1 203.9012,-50.1 203.9012,-.5 13.6066,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"39.0968\" y=\"-21.1\">Dense</text>\n",
       "<polyline fill=\"none\" points=\"64.587,-.5 64.587,-50.1 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"92.4229\" y=\"-33.5\">input:</text>\n",
       "<polyline fill=\"none\" points=\"64.587,-25.3 120.2588,-25.3 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"92.4229\" y=\"-8.7\">output:</text>\n",
       "<polyline fill=\"none\" points=\"120.2588,-.5 120.2588,-50.1 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"162.08\" y=\"-33.5\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"120.2588,-25.3 203.9012,-25.3 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"161.58\" y=\"-8.7\">(None, 2)</text>\n",
       "</g>\n",
       "<!-- 4957863104&#45;&gt;5183082848 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>4957863104-&gt;5183082848</title>\n",
       "<path d=\"M108.7539,-86.8517C108.7539,-78.5937 108.7539,-69.2517 108.7539,-60.3864\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"112.254,-60.292 108.7539,-50.292 105.254,-60.292 112.254,-60.292\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pydot\n",
    "import graphviz\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(w2v_dnn, show_shapes=True, show_layer_names=False, \n",
    "                 rankdir='TB').create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model training Prediction and Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_4 to have shape (1,) but got array with shape (3,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-5eb79d4c5547>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m w2v_dnn.fit(avg_wv_train_features, y_train, epochs=5, batch_size=batch_size, \n\u001b[0;32m----> 7\u001b[0;31m             shuffle=True, validation_split=0.1, verbose=1)\n\u001b[0m",
      "\u001b[0;32m/Users/Alexandra/anaconda/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/Users/Alexandra/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1631\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Alexandra/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1481\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1482\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m/Users/Alexandra/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    121\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_4 to have shape (1,) but got array with shape (3,)"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "print(y_train)\n",
    "#y=keras.utils.to_categorical(y_train, num_classes=1)\n",
    "#print(y)\n",
    "\n",
    "w2v_dnn.fit(avg_wv_train_features, y_train, epochs=5, batch_size=batch_size, \n",
    "            shuffle=True, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
